---
title: "2. Multiple Regression"
author: Dale Barr
institute: University of Glasgow
title-slide-attributes:
  data-background-image: titlescreen.png
format: 
  revealjs:
    theme: dark
    code-line-numbers: false
    df-print: kable
knitr:
  opts_chunk:
    echo: true
---

```{r}
#| label: setup
#| include: false

options(tidyverse.quiet=TRUE)
library("lme4")
library("readxl")
library("tidyverse")

options(width = 60)

source("../theme_jetblack.R")

set.seed(62)

dat <- read_excel("final_dataset.xlsx")

.cnames <- c("grade", "GPA", "lecture", "nclicks")
.cmx <- matrix(.3, nrow = 4, ncol = 4,
               dimnames = list(.cnames, .cnames))
diag(.cmx) <- 1
.sds <- c(1, 1, 2, 15)
for (i in 1:nrow(.cmx)) {
  for (j in 1:ncol(.cmx)) {
    .cmx[i, j] <- .cmx[i, j] * .sds[i] * .sds[j]
  }
}

.grades <- MASS::mvrnorm(100,
                         c(grade = 2.5, GPA = 2.5, lecture = 7, nclicks = 100),
                         .cmx) %>%
  as_tibble() %>%
  mutate(grade = case_when(grade < 0 ~ 0,
                           grade > 4 ~ 4,
                           TRUE ~ grade),
         GPA = case_when(GPA < 0 ~ 0,
                         GPA > 4 ~ 4,
                         TRUE ~ GPA),
         lecture = case_when(lecture < 0 ~ 0L,
                             lecture > 10 ~ 10L,
                             TRUE ~ as.integer(round(lecture))),
         nclicks = as.integer(round(nclicks)))

dir.create("data", FALSE)
write_csv(.grades, "data/grades.csv")
```

## Moving beyond simple regression

- dealing with multiple predictors
- model comparison
- coding categorical predictors

## Multiple regression

General model for single-level data with $m$ predictors:

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i$$

individual $X$s can be any combination of continuous and categorical predictors (and their interactions)

Each $\beta_j$ is the *partial effect of $X_{j}$ holding all other $X$s constant*

::: {.aside}
NB: single-level data is rare in psychology
:::

## Example

Are lecture attendance and engagement with online materials associated with higher grades in statistics?

Does this relationship hold after controlling for overall GPA?

## Import

[`grades.csv`](data/grades.csv){target="_download"}

```{r}
#| label: import-grades
#| output-location: fragment
grades <- read_csv("data/grades.csv", col_types = "ddii")

grades
```

## Correlations

```{r}
#| label: grades-corr
#| output-location: fragment
library("corrr")

grades %>%
  correlate() %>%
  shave() %>%
  fashion()
```

## Visualization

```{r}
#| fig-width: 4
#| fig-height: 4
pairs(grades)
```

## Estimation

$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i$$

`lm(Y ~ X1 + X2 + ... + Xm, data)`

```{r}
my_model <- lm(grade ~ lecture + nclicks, grades)
```

## Output

```{r}
summary(my_model)
```

## Standardized coefficients

```{r}
#| label: standardize
#| output-location: slide
grades2 <- grades %>%
  mutate(lecture_c = (lecture - mean(lecture)) / sd(lecture),
         nclicks_c = (nclicks - mean(nclicks)) / sd(nclicks))

summary(lm(grade ~ lecture_c + nclicks_c, grades2))
```

## Model comparison

Is engagement (as measured by lecture attendance and downloads) positively associated with final course grade *above and beyond* student ability (as measured by GPA)?

## Strategy

Compare "base" model with control vars to a "bigger" model with control plus focal vars

```{r}
base_model <- lm(grade ~ GPA, grades)
big_model <- lm(grade ~ GPA + lecture + nclicks, grades)

anova(base_model, big_model)
```

$$F(2, 96) = 1.31, p = .275$$

If $p < \alpha$, bigger model is better.

## `update()`

```{r}
#| label: model-compare
#| df-print: default
base_model <- lm(grade ~ GPA, grades)
big_model <- update(base_model, . ~ . +lecture +nclicks)

anova(base_model, big_model)
```

## Dummy coding binary vars

Arbitrarily assign one of the two levels to 0; assign the other to 1.

```{r}
#| label: example
#| eval: false
newvar = if_else(oldvar == "targetlevel", 1, 0)
```

See `dplyr::if_else()`

::: {.aside}
*NB: sign of the variable depends on the coding!*
:::
