---
title: "1. Introduction"
author: Dale Barr
institute: University of Glasgow
title-slide-attributes:
  data-background-image: titlescreen.png
format: 
  revealjs:
    theme: dark
    code-line-numbers: false
    df-print: kable
knitr:
  opts_chunk:
    echo: true
---

```{r}
#| label: setup
#| include: false

options(tidyverse.quiet=TRUE)
library("tidyverse")
library("lme4")

options(width = 60)

source("../theme_jetblack.R")
```

---

::: {.r-fit-text}
How do I translate a (longitudinal) study design into a statistical model for analysis?
:::

::: {.notes}
- many of the problems people have with longitudinal designs reflect a lack of understanding of regression or of mixed-effects modeling
:::

---

::: {.notes}
- cooking analogy
- punching buttons on a microwave (pre-packaged food)
- versus taking fresh ingredients and improvising something
:::

![](studyres-com.png)

## Recipes encourage poor practice

- violation of assumptions
  - especially: independence
- discretization of predictors
- treating continuous data as categorical
- over-aggregation

::: {.notes}
 /"If all you have is a hammer, everything looks like a nail"/

- mindless statistics
:::

---

- t-test
- correlation & regression
- multiple regression
- analysis of variance
- mixed-effects modeling

. . .

*All are special cases of the General Linear Model (GLM).*

## GLM approach

1. Define a mathematical model of the data-generating process (DGP)
2. Estimate the parameters of the model
3. Validate the model
4. Report and interpret results

::: {.notes}
representing the processes that are assumed to give rise to the data
:::

## Models are just... models

A statistical model is a *simplification* and *idealization* of reality that captures our key assumptions about the processes underlying data (the *data generating process* or DGP).

## Why simulation?

- Data simulation is a *litmus test* of understanding a statistical approach.
  - Can you generate simulated data that would meet the assumptions of the approach?
    - If not, *you don't understand it (yet!)*

- Being able to specify the DGP is key to study planning (power)

## Example: Parent reflexes

*Does being the parent of a toddler sharpen your reflexes?*

- simple response time to a flashing light
- dependent (response) variable: mean RT for each parent

## Simulating data

```{r}
#| label: parent-reflex-sim
set.seed(2022) # RNG seed: arbitrary integer value
parents <- rnorm(n = 50, mean = 490, sd = 40)
```

. . .

```{r}
#| label: parent-reflex-show
#| echo: false
parents
```

. . .

```{r}
#| label: control-reflex-sim
control <- rnorm(n = 50, mean = 500, sd = 40)
```

. . .

```{r}
#| label: control-reflex-show
#| echo: false
control
```

## $t$-test

```{r}
#| label: t-test
t_result <- t.test(parents, control, var.equal = TRUE)
```

. . .

```{r}
#| label: hid-ttest
#| echo: false
t_result
```

## Analysis of Variance

```{r}
#| label: anova-setup
## put vectors in a data frame with a 'group' label
dat <- tibble(group = rep(c("parent", "control"), 
                          c(length(parents), 
                            length(control))),
              rt = c(parents, control))
```

. . .

```{r}
#| label: anova-run
aov_mod <- aov(rt ~ group, dat)
```

. . .

```{r}
summary(aov_mod)
```

## Regression

$$Y_i = \beta_0 + \beta_1 X_i + e_i$$

$$e_i \sim N(0, \sigma^2)$$

. . .

```{r}
#| label: regression-run
mod <- lm(rt ~ group, dat)
```

. . .

```{r}
#| label: regression-show
#| output-location: slide
summary(mod)
```

## GLM web app

<https://rstudio-connect.psy.gla.ac.uk/GLM>

---

:::: {.columns}

::: {.column width="50%"}

**Single-level data**

```{r}
#| label: hid-single-lvl
#| echo: false
tibble(sub = 1:6,
       A = rep(c("A1", "A2"), each = 3),
       Y = round(rnorm(6, 800, 100)))
```

:::

::: {.column width="50%"}

**Multi-level data**

```{r}
#| label: multilevel-data
#| echo: false
tibble(sub = rep(1:2, each = 3),
       stim = rep(LETTERS[1:3], 2),
       A = rep(c("A1", "A2"), each = 3),
       Y = round(rnorm(6, 800, 100)))
```

:::

::::

## Issues with multi-level data

- GLMs assume independence of residuals
- Observations within a cluster (unit) are not independent
- Any sources of non-independence must be modeled or aggregated away
- Typical consequence of failing to do so: High false positives

## Regression: Killer App

| technique        | t-test | ANOVA | regression |
|:-----------------|:------:|:-----:|:----------:|
| Categorical IVs  | ✓      | ✓     | ✓          |
| Continuous DVs   | ✓      | ✓     | ✓          |
| Continuous IVs   |        | -     | ✓          |
| Multi-level data | -      | -     | ✓          |
| Categorical DVs  |        |       | ✓          |
| Unbalanced data  | -      | -     | ✓          |
| >1 sampling unit |        |       | ✓          |

## 4 functions to rule them all

1. Is the data single- or multi-level?
2. Is the response continuous or discrete?
3. How are the observations distributed?

| structure | response  | distrib | R fnc           |
|:----------|:----------|:--------|-----------------|
| single    | cont      | normal  | `base::lm()`    |
| single    | cont/disc | various | `base::glm()`   |
| multi     | cont      | normal  | `lme4::lmer()`  |
| multi     | cont/disc | various | `lme4::glmer()` |
